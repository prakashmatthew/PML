{
    "collab_server" : "",
    "contents" : "#29-11-17 Hbd Alice\n#train <- read.csv(\"~/pml-training\")\ntrain <- read.csv(\"pml-training.csv\")\ntest <- read.csv(\"pml-testing.csv\")\n\nlibrary(caret)\nintrain <- createDataPartition(y=train$classe, p = 0.7, list = FALSE)\ntrain1 <- train[intrain,]\ntest1 < - train[-intrain,]\nsummary(train1)\ntitles(train1)\n??titles\nc<- intersect(colnames(test), colnames(train))\n?c\ncin<- intersect(colnames(test), colnames(train))\nsummary(train1[,-colnames(c((cin)))])\n\nwhatt <-  test[which(!(colnames(test)%in%cin)),]\ncolnames(test)\ntest$problem_id\ncolnames(train[which(!(colnames(test)==colnames(train)))])\n#the last column of test data is labelled problems_id\n \n#put it all in?\n\n#model1 <- train(classe~. , method = \"rf\", data = train1)\n#bad idea..taking forever\npredict_model1 <- predict(model1, test1)\nlength(predict_model1)\nconfusionMatrix(test1$classe, predict(model1, test1))\npredict(model1, test1)\nsummary(train1$classe)\nmodel1\ntest1_1 <- test1\ntest1_1 <- test1_1[,-c(160)]\nconfusionMatrix(test1$classe, predict(model1, test1_1))\npredict_model1 <- (predict(model1, newdata = test1_1))\nlength(predict_model)\nsummary(train1)\ntrain1_adelmo <- train1[which(train1$user_name == \"adelmo\"),]\ntrain1_carlitos <- train1[which(train1$user_name == \"carlitos\"),]\ntrain1_charles <- train1[which(train1$user_name == \"charles\"),]\ntrain1_eurico <- train1[which(train1$user_name == \"eurico\"),]\ntrain1_jeremy <- train1[which(train1$user_name == \"jeremy\"),]\ntrain1_pedro <- train1[which(train1$user_name == \"pedro\"),]\nsummary(train1$user_name)\n\n#rpart\nlibrary(caret)\nmodel_rpart1 <- train(classe ~ . , method = \"rpart\", data = train1_adelmo)\nmodel_rpart1$finalModel\nlibrary(rattle)\nfancyRpartPlot(model_rpart1$finalModel)\ntest1_adelmo <- test1[which(test1$user_name == \"adelmo\"),]\npredict1_adelmo <- predict(model_rpart1, test1_adelmo)\nconfusionMatrix(predict1_adelmo, test1_adelmo$classe)\nlength(predict1_adelmo)\nview(test1_adelmo)\n\n#correlation\n\ntrain2 <- train[,-c(1:7,160)]\ncorre<- abs(cor(train2[,]))\ncn <- colnames(train)\n\nlength(train[!complete.cases(train),])\n\nnull1 <- data.frame(cn)\nfor(i in 1:160) {\n \n  null1[i,2] <- sum((train[,i]== \"\"))}\n\nfor(i in 1:160) {\n  \n  null1[i,3] <- sum(is.na(train[,i]))}\n\n\ntrain6 <- na.omit(train)\ntable(train6$user_name)\n\n#based on null deleted columns with large missing values ASSUMING limited/inconsistent predictive capabilities\ntrain3 <- train[,-c(1,2:7,12:17,20,23,26,69:74,87:92,95,98,101,125:130,133,136,139)]\n\n#actual correlation\ncorre <- abs(cor((train3[,-c(1,120)]),,))\ndiag(corre) <- 0\nwhich(corre>0.8, arr.ind = T)\n\nm.rp.2 <- train(classe ~ . , method = \"rpart\", data = train3)\nlibrary(rattle)\nfancyRpartPlot(m.rp.2$finalModel)\n\nm.rf.2 <- train(classe ~ . , method = \"rf\", data = train3)\np3 <- predict(m.rf.2,newdata = test1)\nlength(p3)\nsummary(p3)\n#replacing NA with 0s (not sure if it's the right thing..hoping to solve the limited no of predictions problem)\ntrain4 <- train3\nfor(i in 1:120){\n  for(j in 1:19622){\n    if(is.na(train4[j,i])){\n      train4[j,i] <- 0\n    }\n  }\n}\nlibrary(caret)\nm.rp.3 <- train(classe ~ . , method = \"rpart\", data = train4)\nlibrary(rattle)\nfancyRpartPlot(m.rp.3$finalModel)\np4 <- predict(m.rp.3, test1)\nlength(p4)\n\n#missing predictions problems not solved :/\ntrain5 <- train1\nfor(i in 1:120){\n  for(j in 1:19622){\n    if(is.na(train5[j,i])){\n      train5[j,i] <- 0\n    }\n  }\n}\n\nm.rp.4 <- train(classe ~ . , method = \"rpart\", data = train5)\nfancyRpartPlot(m.rp.4$finalModel)\np.rp.4 <- predict(m.rp.4, test1)\nlength(p.rp.4)\n\n\ntrain6 <- na.omit(train)\nm.rp.5 <- train(classe ~ . , method = \"rpart\", data = train6)\n fancyRpartPlot(m.rp.5$finalModel)\n \np.rp.5 <- predict(m.rp.5, newdata = test)\n\n\nm.ct.1<- train(classe ~ . , method = \"cart\", data = train6)\np.ct.1<- predict(m.ct.1, newdata = test)\n\nlength(p.rp.5)\nlength(p.ct.1)\n\ntest6 <- test\nfor(i in 1:120){\n  for(j in 1:6){\n    if(is.na(train5[j,i])){\n      test6[j,i] <- 0\n    }\n  }\n}\n\np.rp.5 <- predict(m.rp.5, newdata = test6)\nwarnings()\n\nnull2 <- data.frame(cn)\nfor(i in 1:160) {\n  \n  null2[i,2] <- sum((test[,i]== \"\"))}\n\nfor(i in 1:160) {\n  \n  null2[i,3] <- sum(is.na(test[,i]))}\n\n#removing columns not present in test data set\ntest7 <- test[,-c(12:36,50:59,69:83,87:101,103:112,125:139,141:150)]\ntrain7 <- train[,-c(12:36,50:59,69:83,87:101,103:112,125:139,141:150)]\n\n#rpart and rf\n\nm.rp.6 <- train(classe ~ . , method = \"rpart\", data = train7)\nlibrary(rattle)\nfancyRpartPlot(m.rp.6$finalModel)\np.rp.6 <- predict(m.rp.6, test7)\n\nm.rf.3 <- train(classe ~ . , method = \"rf\", data = train7)\np.rf.3 <- predict(m.rf.3, test7)\nlength(p.rp.6)\nlength(p.rf.3)\n\n#the predictions are all A :/\n\n#removing X\ntrain8 <- train7[,-1]\ntest8 <- test7[,-1]\n\n\n\n#cross-validation 3 fold 5 times\n\ntrain9 <- train8[,-59]\ntrain.label <- as.factor(train8$classe)\n\ncv.3folds <- createMultiFolds(train.label, k = 3, times = 5)\nctrl1 <- trainControl(method = \"repeatedcv\", number = 3, repeats = 5, index = cv.3folds)\n\nlibrary(doSNOW)\ncl <- makeCluster(3, type = \"SOCK\")\nregisterDoSNOW(cl)\nm.rf.5 <- train( x = train9, y = train.label, method = \"rf\", trControl = ctrl1)\n\nstopCluster(cl)\n\ntest9 <- test8[,-59]\nm.rf.5$finalModel\n\n#Type of random forest: classification\n#Number of trees: 500\n#No. of variables tried at each split: 30\n\n#OOB estimate of  error rate: 0.07%\n#Confusion matrix:\n#  A    B    C    D    E  class.error\n#A 5580    0    0    0    0 0.0000000000\n#B    1 3795    1    0    0 0.0005267316\n#C    0    3 3418    1    0 0.0011689071\n#D    0    0    4 3210    2 0.0018656716\n#E    0    0    0    2 3605 0.0005544774\n\nm.rf.4 <- train(classe ~ . , method = \"rf\", data = train8)\np.rf.4 <- predict(m.rf.4, test8)\np.rf.4\n\n#mtry  Accuracy   Kappa    \n#2    0.9905045  0.9879890\n#41    0.9991620  0.9989403\n#80    0.9983589  0.9979248\n#Accuracy was used to select the optimal model using  the largest value.\n#The final value used for the model was mtry = 41.\n\n#m.rf.4 has all the 20 test variables correctly predicted",
    "created" : 1511939752328.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4207216676",
    "id" : "1D53DA31",
    "lastKnownWriteTime" : 1513701028,
    "last_content_update" : 1513701028385,
    "path" : "C:/Users/hp laptop/Downloads/PML/PML1.R",
    "project_path" : "PML1.R",
    "properties" : {
        "docOutlineVisible" : "0",
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}